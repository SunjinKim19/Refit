from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
import json
import numpy as np
import os

# 1. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_model_name = "jhgan/ko-sbert-sts"
embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)

category = input("ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”\nAS, business, change, order, payment, return, shipping\n: ")
print()

# 2. ì €ì¥ëœ JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
with open(f'backend/embeddings/{category}_docs_with_intent.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# 3. Document ê°ì²´ ì¬ìƒì„± ë° ì„ë² ë”© ë²¡í„° ë¶„ë¦¬
docs = []
embeddings = []

for item in data:
    metadata = item["metadata"].copy()
    embedding = np.array(metadata.pop("embedding"), dtype=np.float32)
    doc = Document(
        page_content=item["page_content"],
        metadata=metadata
    )
    docs.append(doc)
    embeddings.append(embedding)

embeddings = np.array(embeddings)

# 4. FAISS ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸°
save_path = f"backend/embeddings/{category}_faiss_index"

if os.path.exists(save_path):
    print("FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    vectorstore = FAISS.load_local(save_path, embedding_model, allow_dangerous_deserialization=True)
else:
    print("FAISS ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„± ì¤‘...")
    vectorstore = FAISS.from_documents(docs, embedding_model)
    os.makedirs(save_path, exist_ok=True)
    vectorstore.save_local(save_path)
    print("FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")

# 5. Retriever ìƒì„± (k=10)
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# 6. ì§ˆì˜ì–´ ì…ë ¥
query = "í¬ì¥ ì–´ë–»ê²Œ í•´ì„œ ë³´ë‚´ì•¼ í•˜ë‚˜ìš”?"

# 7. í›„ë³´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
candidate_docs = retriever.invoke(query)

# 8. CrossEncoder ë¡œ ìœ ì‚¬ë„ ì§ì ‘ ê³„ì‚°
cross_encoder = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-v2-m3")
pairs = [(query, doc.page_content) for doc in candidate_docs]
scores = cross_encoder.score(pairs)

# 9. ì ìˆ˜ë¥¼ ë¬¸ì„œì— ë¶™ì´ê³  ì •ë ¬
scored_docs = sorted(zip(candidate_docs, scores), key=lambda x: x[1], reverse=True)

# 10. ìƒìœ„ 3ê°œ ë¬¸ì„œ ì¶œë ¥
print("\nğŸ¯ [ìƒìœ„ 3ê°œ í›„ë³´ ì¶œë ¥ - ìœ ì‚¬ë„ í¬í•¨]")
for i, (doc, score) in enumerate(scored_docs[:3], 1):
    print(f"{i}. ì§ˆë¬¸: {doc.metadata.get('question', 'ì—†ìŒ')}")
    print(f"   â†³ ë‹µë³€: {doc.metadata.get('answer', 'ì—†ìŒ')}")
    print(f"   ğŸ§­ ê³ ê°ì˜ë„: {doc.metadata.get('intent', 'ì—†ìŒ')}")
    print(f"   ğŸ“Š ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}")
    print("-" * 50)

