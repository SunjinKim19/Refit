from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CrossEncoderReranker
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
import json
import numpy as np
import os


# 1. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_model_name = "jhgan/ko-sbert-sts"
embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)

category = input("ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”\nAS, business, change, order, payment, return, shipping\n: ")
print()
# 2. ì €ì¥ëœ JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
with open(f'backend/embeddings/{category}_docs_with_intent.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# 3. Document ê°ì²´ ì¬ìƒì„± ë° ì„ë² ë”© ë²¡í„° ë¶„ë¦¬
docs = []
embeddings = []

for item in data:
    metadata = item["metadata"].copy()
    embedding = np.array(metadata.pop("embedding"), dtype=np.float32)  # âœ… embeddingë§Œ ë¶„ë¦¬
    doc = Document(
        page_content=item["page_content"],
        metadata=metadata  # âœ… question, answer, intentëŠ” ìœ ì§€
    )
    docs.append(doc)
    embeddings.append(embedding)

embeddings = np.array(embeddings)

# 4. FAISS ì¸ë±ìŠ¤ ìƒì„± (from_embeddings ì‚¬ìš©)
save_path = f"backend/embeddings/{category}_faiss_index"

if os.path.exists(save_path):
    print("FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    vectorstore = FAISS.load_local(save_path, embedding_model, allow_dangerous_deserialization=True)

else:
    print("FAISS ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„± ì¤‘...")
    vectorstore = FAISS.from_documents(docs, embedding_model)
    os.makedirs(save_path, exist_ok=True)
    vectorstore.save_local(save_path)
    print("FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")

# 5. Retriever ìƒì„± (k=10)
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

# 6. ì§ˆì˜ì–´ ì…ë ¥
query = "ê²°ì œ ë„ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë‚¬ì–´ìš”."

# ëª¨ë¸ ì´ˆê¸°í™”
model = HuggingFaceCrossEncoder(model_name="BAAI/bge-reranker-v2-m3")

# ìƒìœ„ 3ê°œì˜ ë¬¸ì„œ ì„ íƒ
compressor = CrossEncoderReranker(model=model, top_n=3)

# ë¬¸ì„œ ì••ì¶• ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor, base_retriever=retriever
)

compressed_docs = compression_retriever.invoke(query)
# 8. ìƒìœ„ 3ê°œ í›„ë³´ ë¬¸ì„œ ì¶œë ¥ (ì ìˆ˜ ì—†ì´)

print("\nğŸ¯ [ìƒìœ„ 3ê°œ í›„ë³´ ì¶œë ¥]")
for i, doc in enumerate(compressed_docs[:3], 1):
    print(f"{i}. ì§ˆë¬¸: {doc.metadata.get('question', 'ì—†ìŒ')}")
    print(f"   â†³ ë‹µë³€: {doc.metadata.get('answer', 'ì—†ìŒ')}")
    print(f"   ğŸ§­ ê³ ê°ì˜ë„: {doc.metadata.get('intent', 'ì—†ìŒ')}")
    print("-" * 50)
